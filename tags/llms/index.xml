<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLMs on Kyungpyo Kim</title>
    <link>https://kyungpyo-kim.github.io/tags/llms/</link>
    <description>Recent content in LLMs on Kyungpyo Kim</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Sun, 18 Aug 2024 16:50:55 +0900</lastBuildDate><atom:link href="https://kyungpyo-kim.github.io/tags/llms/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[paper] flash attention review</title>
      <link>https://kyungpyo-kim.github.io/study/flash_attention/</link>
      <pubDate>Sun, 18 Aug 2024 16:50:55 +0900</pubDate>
      
      <guid>https://kyungpyo-kim.github.io/study/flash_attention/</guid>
      
        <description>Overview 저는 현재 LLM 을 포함한 AI 모델, 그리고 이를 효율적으로 처리하기 위한 NPU/GPU 관련된 업무들을 다양하게 진행해 오고 있습니다.</description>
      
    </item>
    
    <item>
      <title>[Paper] 1-bit Large Language Models (LLMs)</title>
      <link>https://kyungpyo-kim.github.io/study/bitnetb1.58/</link>
      <pubDate>Sun, 03 Mar 2024 22:42:57 +0900</pubDate>
      
      <guid>https://kyungpyo-kim.github.io/study/bitnetb1.58/</guid>
      
        <description>최근 LinkedIn 에서 많이 언급되는 논문이 발표되어 간단하게 살펴본다. 제목이 자극적이긴 하다.</description>
      
    </item>
    
  </channel>
</rss>